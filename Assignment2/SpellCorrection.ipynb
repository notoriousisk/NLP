{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Iskander Ishkineev BS-AI-01**"
      ],
      "metadata": {
        "id": "AxSfYKk_C8-h"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIgM6C9HYUhm"
      },
      "source": [
        "# Context-sensitive Spelling Correction\n",
        "\n",
        "The goal of the assignment is to implement context-sensitive spelling correction. The input of the code will be a set of text lines and the output will be the same lines with spelling mistakes fixed.\n",
        "\n",
        "Submit the solution of the assignment to Moodle as a link to your GitHub repository containing this notebook.\n",
        "\n",
        "Useful links:\n",
        "- [Norvig's solution](https://norvig.com/spell-correct.html)\n",
        "- [Norvig's dataset](https://norvig.com/big.txt)\n",
        "- [Ngrams data](https://www.ngrams.info/download_coca.asp)\n",
        "\n",
        "Grading:\n",
        "- 60 points - Implement spelling correction\n",
        "- 20 points - Justify your decisions\n",
        "- 20 points - Evaluate on a test set\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-vb8yFOGRDF"
      },
      "source": [
        "## Implement context-sensitive spelling correction\n",
        "\n",
        "Your task is to implement context-sensitive spelling corrector using N-gram language model. The idea is to compute conditional probabilities of possible correction options. For example, the phrase \"dking sport\" should be fixed as \"doing sport\" not \"dying sport\", while \"dking species\" -- as \"dying species\".\n",
        "\n",
        "The best way to start is to analyze [Norvig's solution](https://norvig.com/spell-correct.html) and [N-gram Language Models](https://web.stanford.edu/~jurafsky/slp3/3.pdf).\n",
        "\n",
        "You may also want to implement:\n",
        "- spell-checking for a concrete language - Russian, Tatar, etc. - any one you know, such that the solution accounts for language specifics,\n",
        "- some recent (or not very recent) paper on this topic,\n",
        "- solution which takes into account keyboard layout and associated misspellings,\n",
        "- efficiency improvement to make the solution faster,\n",
        "- any other idea of yours to improve the Norvigâ€™s solution.\n",
        "\n",
        "IMPORTANT:  \n",
        "Your project should not be a mere code copy-paste from somewhere. You must provide:\n",
        "- Your implementation\n",
        "- Analysis of why the implemented approach is suggested\n",
        "- Improvements of the original approach that you have chosen to implement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MoQeEsZvHvvi"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import string\n",
        "import difflib\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "words = []\n",
        "bigrt = {}\n",
        "with open('bigrams.txt', 'r', encoding='latin-1') as file:\n",
        "  lines = file.readlines()\n",
        "  for i in lines:\n",
        "    i = i.strip().split(\"\\t\")\n",
        "    words.append(i[1])\n",
        "    words.append(i[2])\n",
        "    bigrt[f\"{i[1]} {i[2]}\"] = i[0]\n",
        "    count += int(i[0])\n",
        "WORDS = Counter(words)"
      ],
      "metadata": {
        "id": "5KvvxMhSSblc"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for key in bigrt:\n",
        "  bigrt[key] = int(bigrt[key])/count"
      ],
      "metadata": {
        "id": "vmE5r9DhU5lC"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def edits1(word):\n",
        "    \"All edits that are one edit away from `word`.\"\n",
        "    letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
        "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
        "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
        "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
        "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
        "    inserts    = [L + c + R               for L, R in splits for c in letters]\n",
        "    return set(deletes + transposes + replaces + inserts)\n",
        "\n",
        "def edits2(word):\n",
        "    \"All edits that are two edits away from `word`.\"\n",
        "    return (e2 for e1 in edits1(word) for e2 in edits1(e1))"
      ],
      "metadata": {
        "id": "C2_dZdo_U-hU"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_first_word(word):\n",
        "    \"Predicts the most probable first word in a sentence. \"\n",
        "    possible_edits = edits1(word)\n",
        "    possible_edits_2 = edits2(word)\n",
        "    candidate_words = set(possible_edits).union(possible_edits_2)\n",
        "\n",
        "    if word in WORDS:\n",
        "        return word\n",
        "\n",
        "    max_count = -1\n",
        "    predicted_word = ''\n",
        "    for candidate in candidate_words:\n",
        "        if candidate in WORDS and WORDS[candidate] > max_count:\n",
        "            max_count = WORDS[candidate]\n",
        "            predicted_word = candidate\n",
        "\n",
        "    return predicted_word"
      ],
      "metadata": {
        "id": "mrvB_HU-Mwx4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word(prev_word, current_word):\n",
        "    \"Predicts the most probable next word given the previous word and the current word.\"\n",
        "    possible_edits = edits1(current_word)\n",
        "    possible_edits_2 = edits2(current_word)\n",
        "    candidate_words = set(possible_edits).union(possible_edits_2)\n",
        "\n",
        "    pair = f\"{prev_word} {current_word}\"\n",
        "    if pair in bigrt:\n",
        "        return current_word\n",
        "\n",
        "    max_probability = -1\n",
        "    predicted_word = ''\n",
        "    for candidate in candidate_words:\n",
        "        candidate_pair = f\"{prev_word} {candidate}\"\n",
        "        if candidate in WORDS:\n",
        "            probability = bigrt.get(candidate_pair, 0)\n",
        "            if probability > max_probability:\n",
        "                max_probability = probability\n",
        "                predicted_word = candidate\n",
        "\n",
        "    if not predicted_word:\n",
        "        for candidate in candidate_words:\n",
        "            if candidate in WORDS:\n",
        "                if WORDS[candidate] > max_probability:\n",
        "                    max_probability = WORDS[candidate]\n",
        "                    predicted_word = candidate\n",
        "\n",
        "    return predicted_word\n"
      ],
      "metadata": {
        "id": "509Oph0-NSx5"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oML-5sJwGRLE"
      },
      "source": [
        "## Justify your decisions"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Bigram datasets was used`\n",
        "since among given datasets, the one with bigrams was the largest, so there was larger variety of words for testing.\n",
        "\n",
        "Also, for this task bigrams are more than sufficient to get the results since the context provided by bigrms is good enough.\n",
        "Moreover bigrams provide high efficiency, compared to higher order grams that are computationally more expensive.\n",
        "\n",
        "\n",
        "If a word or gram appears at the beginning or middle of an N-gram, its probability is determined by dividing 1 by the sum of all counts of bigrams (which can alternatively be expressed as the number of distinct known words). Conversely, if the word or gram is positioned at the end of an N-gram, its probability is calculated by dividing 1 by the sum of counts of known bigrams that can be formed from the preceding gram.\n",
        "\n",
        "My solution utilizes a combination of edits on the input word, frequency counts of words, and probabilities from a bigram model to predict the most likely corrections or next words.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1x6f5cPp9_QP"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46rk65S4GRSe"
      },
      "source": [
        "## Evaluate on a test set\n",
        "\n",
        "Your task is to generate a test set and evaluate your work. You may vary the noise probability to generate different datasets with varying compexity. Compare your solution to the Norvig's corrector, and report the accuracies."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def mutate_word(word):\n",
        "    alphabet = 'abcdefghijklmnopqrstuvwxyz'\n",
        "\n",
        "    action = np.random.randint(0, 3)\n",
        "\n",
        "    if action == 0:\n",
        "        # replace a letter\n",
        "        word = list(word)\n",
        "        word[np.random.randint(0, len(word))] = alphabet[np.random.randint(0, 26)]\n",
        "        word = ''.join(word)\n",
        "    elif action == 1 and len(word) > 1:\n",
        "        # remove a letter\n",
        "        rem_index = np.random.randint(0, len(word))\n",
        "        word = word[:rem_index] + word[rem_index+1:]\n",
        "    else:\n",
        "        # add a letter\n",
        "        word = word + alphabet[np.random.randint(0, 26)]\n",
        "\n",
        "    return word"
      ],
      "metadata": {
        "id": "fE-GsUaYdwcz"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "simple_sentences = [\n",
        "    \"It was raining outside\",\n",
        "    \"They tried to do the math test\",\n",
        "    \"I am always annoyed by the loud noises\",\n",
        "    \"They want to try this cake\",\n",
        "    \"The ship cuts through the vast expanse of the ocean\",\n",
        "    \"He works together with crew members\",\n",
        "    \"The sun hangs high in the sky\",\n",
        "    \"The smell of fresh bread fills the kitchen\",\n",
        "    \"Snowflakes dance in the winter air\",\n",
        "    \"Stars twinkle in the night sky\"\n",
        "]\n",
        "\n",
        "split_sentences = []\n",
        "for sentence in simple_sentences:\n",
        "    split_sentences.append(sentence.lower().split())\n",
        "\n",
        "edited_sentences = []\n",
        "for sentence in split_sentences:\n",
        "  mutated_sentence = \"\"\n",
        "  for word in sentence:\n",
        "    mutate = random.randint(0, 1)\n",
        "    if mutate > 0:\n",
        "      mutated_sentence += mutate_word(mutate_word(word)) + \" \"\n",
        "    else:\n",
        "      mutated_sentence += word + \" \"\n",
        "  edited_sentences.append(mutated_sentence[:-1])\n",
        "\n",
        "print(split_sentences)\n",
        "print(edited_sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCh-o7FvTJed",
        "outputId": "2d5675c3-9e00-4297-b51b-125ae68777d7"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['it', 'was', 'raining', 'outside'], ['they', 'tried', 'to', 'do', 'the', 'math', 'test'], ['i', 'am', 'always', 'annoyed', 'by', 'the', 'loud', 'noises'], ['they', 'want', 'to', 'try', 'this', 'cake'], ['the', 'ship', 'cuts', 'through', 'the', 'vast', 'expanse', 'of', 'the', 'ocean'], ['he', 'works', 'together', 'with', 'crew', 'members'], ['the', 'sun', 'hangs', 'high', 'in', 'the', 'sky'], ['the', 'smell', 'of', 'fresh', 'bread', 'fills', 'the', 'kitchen'], ['snowflakes', 'dance', 'in', 'the', 'winter', 'air'], ['stars', 'twinkle', 'in', 'the', 'night', 'sky']]\n",
            "['ity walg rainingtt outsidvl', 'wheyn trgedq jk doqp the math tesvu', 'i am always annoyed baf the loud noireu', 'thyyi wantxc to try this cake', 'the skipj utsz hroughm rh vamt epanse ofzj tter ocean', 'he works togeherl witn crew members', 'the sun hangs high ingx the sky', 'bhe smell pfi tesh bread filgso the kjtchn', 'snowfzakest dance in the winter aiq', 'stars twinkle ik te night sky']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def similarity(s1, s2):\n",
        "    matcher = difflib.SequenceMatcher(None, s1.lower(), s2.lower())\n",
        "    return matcher.ratio()"
      ],
      "metadata": {
        "id": "mtawA3UaVR5Y"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count = len(edited_sentences)\n",
        "total = 0\n",
        "\n",
        "for k in range(len(edited_sentences)):\n",
        "  corrected = ''\n",
        "  for i in range(len(edited_sentences[k].split())):\n",
        "    start = time.time()\n",
        "    if i == 0:\n",
        "      corrected += predict_first_word(edited_sentences[k].split()[i]) + ' '\n",
        "      current_word = predict_first_word(edited_sentences[k].split()[i])\n",
        "    else:\n",
        "      corrected += predict_next_word(current_word, edited_sentences[k].split()[i])+ ' '\n",
        "      current_word = predict_next_word(current_word, edited_sentences[k].split()[i])\n",
        "  corrected = corrected[:-1]\n",
        "  print(\"Sentence before: \", edited_sentences[k])\n",
        "  print(\"Sentence after: \", corrected)\n",
        "  print(\"Correct sentence: \", simple_sentences[k])\n",
        "  similarity_score = similarity(corrected, simple_sentences[k])\n",
        "  print(\"Similarity score\", similarity_score)\n",
        "  total += similarity_score\n",
        "\n",
        "overall_accuracy = total / count\n",
        "print(\"Overall accuracy:\", overall_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxvBVvIDVUO4",
        "outputId": "c340d626-8bf9-4f8a-c153-7a9c6d6c6c45"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence before:  ity walg rainingtt outsidvl\n",
            "Sentence after:  to talk raining outside\n",
            "Correct sentence:  It was raining outside\n",
            "Similarity score 0.8444444444444444\n",
            "Sentence before:  wheyn trgedq jk doqp the math tesvu\n",
            "Sentence after:  they tried to do the math test\n",
            "Correct sentence:  They tried to do the math test\n",
            "Similarity score 1.0\n",
            "Sentence before:  i am always annoyed baf the loud noireu\n",
            "Sentence after:  i am always enjoyed a the loud noise\n",
            "Correct sentence:  I am always annoyed by the loud noises\n",
            "Similarity score 0.8918918918918919\n",
            "Sentence before:  thyyi wantxc to try this cake\n",
            "Sentence after:  they want to try this cake\n",
            "Correct sentence:  They want to try this cake\n",
            "Similarity score 1.0\n",
            "Sentence before:  the skipj utsz hroughm rh vamt epanse ofzj tter ocean\n",
            "Sentence after:  the ship its rough on at ease of the ocean\n",
            "Correct sentence:  The ship cuts through the vast expanse of the ocean\n",
            "Similarity score 0.8387096774193549\n",
            "Sentence before:  he works togeherl witn crew members\n",
            "Sentence after:  he works together in new members\n",
            "Correct sentence:  He works together with crew members\n",
            "Similarity score 0.8955223880597015\n",
            "Sentence before:  the sun hangs high ingx the sky\n",
            "Sentence after:  the sun has high in the sky\n",
            "Correct sentence:  The sun hangs high in the sky\n",
            "Similarity score 0.9642857142857143\n",
            "Sentence before:  bhe smell pfi tesh bread filgso the kjtchn\n",
            "Sentence after:  the smell of the bread fils t kitchen\n",
            "Correct sentence:  The smell of fresh bread fills the kitchen\n",
            "Similarity score 0.8860759493670886\n",
            "Sentence before:  snowfzakest dance in the winter aiq\n",
            "Sentence after:  snowflakes dandy in the winter and\n",
            "Correct sentence:  Snowflakes dance in the winter air\n",
            "Similarity score 0.8823529411764706\n",
            "Sentence before:  stars twinkle ik te night sky\n",
            "Sentence after:  stars wrinkle in the night sky\n",
            "Correct sentence:  Stars twinkle in the night sky\n",
            "Similarity score 0.9666666666666667\n",
            "Overall accuracy: 0.9169949673311333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Norvig's solution"
      ],
      "metadata": {
        "id": "vlxNAPfTBF3_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def words(text): return re.findall(r'\\w+', text.lower())\n",
        "\n",
        "file = open('big.txt').read()\n",
        "WORDS = Counter(words(file))\n",
        "\n",
        "def P(word, N=sum(WORDS.values())):\n",
        "    \"Probability of `word`.\"\n",
        "    return WORDS[word] / N\n",
        "\n",
        "def known(words):\n",
        "    \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
        "    return set(w for w in words if w in WORDS)\n",
        "\n",
        "def edits1(word):\n",
        "    \"All edits that are one edit away from `word`.\"\n",
        "    letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
        "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
        "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
        "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
        "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
        "    inserts    = [L + c + R               for L, R in splits for c in letters]\n",
        "    return set(deletes + transposes + replaces + inserts)\n",
        "\n",
        "def edits2(word):\n",
        "    \"All edits that are two edits away from `word`.\"\n",
        "    return (e2 for e1 in edits1(word) for e2 in edits1(e1))\n",
        "\n",
        "\n",
        "def candidates(word):\n",
        "    \"Generate possible spelling corrections for word.\"\n",
        "    return (known([word]).union(known(edits1(word))) or known(edits2(word)) or [word])\n",
        "\n",
        "def correction(word):\n",
        "    \"Most probable spelling correction for word.\"\n",
        "    return max(candidates(word), key=P)"
      ],
      "metadata": {
        "id": "caJ9xPi-BE8E"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count = len(edited_sentences)\n",
        "total = 0\n",
        "\n",
        "for k in range(len(edited_sentences)):\n",
        "  corrected = ''\n",
        "  for i in range(len(edited_sentences[k].split())):\n",
        "    start = time.time()\n",
        "    if i == 0:\n",
        "      corrected += correction(edited_sentences[k].split()[i]) + ' '\n",
        "      prev_word = correction(edited_sentences[k].split()[i])\n",
        "    else:\n",
        "      corrected += correction(edited_sentences[k].split()[i]) + ' '\n",
        "      prev_word = correction(edited_sentences[k].split()[i])\n",
        "  corrected = corrected[:-1]\n",
        "  print(\"Sentence before: \", edited_sentences[k])\n",
        "  print(\"Sentence after: \", corrected)\n",
        "  print(\"Correct sentence: \", simple_sentences[k])\n",
        "  similarity_score = similarity(corrected, simple_sentences[k])\n",
        "  print(\"Similarity score\", similarity_score)\n",
        "  total += similarity_score\n",
        "\n",
        "overall_accuracy = total / count\n",
        "print(\"Overall accuracy:\", overall_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHCqDEmxBRDV",
        "outputId": "3f3719cf-93c9-4505-c658-ad8f10ca32e9"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence before:  tw was raining oxtsidea\n",
            "Sentence after:  to was raising outside\n",
            "Correct sentence:  It was raining outside\n",
            "Similarity score 0.9090909090909091\n",
            "Sentence before:  they tried d do khev math tekh\n",
            "Sentence after:  the cried a to kiev path takh\n",
            "Correct sentence:  They tried to do the math test\n",
            "Similarity score 0.6440677966101694\n",
            "Sentence before:  i am alys annoyedoc by the lou qoises\n",
            "Sentence after:  in a alms annoyed by the you horses\n",
            "Correct sentence:  I am always annoyed by the loud noises\n",
            "Similarity score 0.821917808219178\n",
            "Sentence before:  bey wacts g tryme this ake\n",
            "Sentence after:  by acts a time his are\n",
            "Correct sentence:  They want to try this cake\n",
            "Similarity score 0.5416666666666666\n",
            "Sentence before:  the shirl cuts through e vast expanse or e ocean\n",
            "Sentence after:  the shirt cut through a last expense of a ocean\n",
            "Correct sentence:  The ship cuts through the vast expanse of the ocean\n",
            "Similarity score 0.8367346938775511\n",
            "Sentence before:  hecn works tmgther wit crww debers\n",
            "Sentence after:  hen words mother it crew members\n",
            "Correct sentence:  He works together with crew members\n",
            "Similarity score 0.8656716417910447\n",
            "Sentence before:  tweu s hangs high in the sky\n",
            "Sentence after:  twue a hands high in the say\n",
            "Correct sentence:  The sun hangs high in the sky\n",
            "Similarity score 0.8070175438596491\n",
            "Sentence before:  thf smell ogl fresh breadwx fills thexk ktche\n",
            "Sentence after:  the small oil fresh bread hills the the\n",
            "Correct sentence:  The smell of fresh bread fills the kitchen\n",
            "Similarity score 0.8641975308641975\n",
            "Sentence before:  snowflakes dance t the winter air\n",
            "Sentence after:  snowflakes dance to the winter hair\n",
            "Correct sentence:  Snowflakes dance in the winter air\n",
            "Similarity score 0.927536231884058\n",
            "Sentence before:  strsb twinkle o thx oiht s\n",
            "Sentence after:  stars twinkled of the it a\n",
            "Correct sentence:  Stars twinkle in the night sky\n",
            "Similarity score 0.7857142857142857\n",
            "Overall accuracy: 0.8003615108577711\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the results above, we can see that:\n",
        "* the Norvig's solution gives accuracy of ~ 80%,\n",
        "* while my modified solution gives accuracy of ~ 90%."
      ],
      "metadata": {
        "id": "kz3H5H5GCdqK"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}